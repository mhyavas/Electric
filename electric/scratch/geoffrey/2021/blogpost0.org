#+PROPERTY: header-args :noweb yes :exports both
#+PROPERTY: header-args:clojure :eval never :tangle blogpost0.cljc :comments both
#+PROPERTY: header-args:dot :exports none
#+EXCLUDE_TAGS: noexport
# #+OPTIONS: toc:nil

#+TITLE: Missionary by example

~miss·io·narry~

#+begin_src clojure :results none
(ns blogpost0
  "Missionary by example"
  (:require [minitest :refer [tests]]
            [missionary.core :as m :refer [? sp ap]]))
#+end_src

# ?! ~ fork-concat

* Tasks

  A task is a value, wrapping a computation. Running a task is "asking" for a
  value, running the wrapped computation and returning the computed value. Tasks
  are assumed to be referencially transparent.

  #+begin_src clojure :results none
  (def my-task (m/sleep 1000)) ; a simple non-blocking sleep task.

  (m/? my-task) ; run or "ask" the task for it's effect. `?` (ask) will block the
                ; current process until a value is available. It is sequential,
                ; like `deref` on `future`.
  #+end_src

  NOTE: Blocking here is just a REPL convenience. You don't need to block in a
  correctly written program.

** Task abstraction

   You can also run a task by calling it as a function, in which case it takes
   two arguments ~(my-task success-callback error-callback)~, where:
   - ~success-callback~ is a one-argument function receiving the produced value
     when the task succeeds,
   - ~error-callback~ is a one-argument function receiving the error object
     (exception) when the task fails.

   #+begin_src clojure :results none
   (my-task (fn [val] (prn :success val))
            (fn [err] (prn :failure err)))
   #+end_src

   ~Task~ is a protocol (convention), it's not a concrete type. The example
   above is quite similar to what the JS promise constructor expects.

** Canceling a task

   Calling ~my-task~ as a function returns a 0-arg control function. Calling it will cancel the task:

   #+begin_src clojure :results none :exports both
   (def my-task (m/sleep 100000)) ; a long task
   (def cancel (my-task (partial prn :success) (partial prn :failure)))
   ;; wait a bit
   (cancel) ; prints ":failure …"
   #+end_src

   Canceling ~my-task~ prints ~:failure …~ because that's how ~m/sleep~ works.

* Sequential composition

  Sequential composition means effects compose by running in order. We could
  describe it as an alternative to monadic composition in [[https://en.wikibooks.org/wiki/Haskell/Understanding_monads/IO][IO]]. It has the same
  exception short-circuit behavior and is the same kind of construct.

  # Task is the same kind of object as haskell's IO except Task doesn't have a
  # type because we are in lisp task :: (v -> IO) -> (err -> IO) -> (-> IO)

  The ~m/sp~ macro stands for Sequential Process. It composes effects
  sequentially and returns a task value:

  #+begin_src clojure :results none
  (def task (m/sp (let [x (m/? (m/sleep 1000 :x))]
                    (println x)
                    x)))
  #+end_src

  If ask (~?~) is used inside an ~sp~ block, it is desugared to a continuation
  and do not block the current thread [fn:1].

  #+begin_src clojure :results none
  (? task) ; can run the task
  (? task) ; can run again, it's reusable value
  #+end_src


* Monad-like composition

  Let's have a simple ~sleep ms value~ tasks which waits for ~ms~ milliseconds,
  print ~value~ and return it:

  #+begin_src clojure :results none
  (defn sleep' [delay v]
    (sp (let [x (? (m/sleep delay v))]
          (println x)
          x)))
  #+end_src

  #+begin_src clojure :exports both
  (sleep' 1000 :x)
  #+end_src

  #+RESULTS:
  : #function[clojure.core/partial/fn--5824]

  The s-expression is gone, it's wrapped in a thunk.

  We can now compose sequentially, with dynamic continuations:

  #+begin_src clojure :results none
  (sp (let [a (? (sleep' 1000 42))]
        (? (if (odd? a)
             (sleep' 1000 a)
             (sleep' 1000 (inc a))))))
  #+end_src

  These sleeps are sequential and thus take two seconds! This is really a
  Clojure problem, could just use two ~Thread/sleeps~ for this:
  #+begin_src clojure :results none
  (sp (vector
       (? (m/sleep 1000 :a))   ; ? will park
       (? (m/sleep 1000 :b))))
  #+end_src

* Parallelism

  The naive approach is to parallelize the sleeps. There's an operator for that:

  #+begin_src clojure :results none
  (def task
    (m/join vector         ; runs in 1 seconds
            (m/sleep 1000 :a)
            (m/sleep 1000 :b)))
  #+end_src

  We don't need the ~sp~ macro here because ~m/join~ expects tasks. Also, the
  ~sp~ macro is about sequential composition and this is now parallel. This is
  no longer a purely sequential process.

  #+begin_src clojure :exports both :results value verbatim
  (? task)
  ;; delay one second
  #+end_src

  #+RESULTS:
  : [:a :b]

  This approach is naive because ~m/sleep~ is a referencially transparent
  operation, so in the following example ~join~ can't know these are the same
  task. A task should run once and the result should be reused.

  #+begin_src clojure :eval never :results none
  (let [x-task (m/sleep 1000 :x)]
        (m/join vector x-task x-task)) ; x-task runs twice, in parallel.
  #+end_src

  Let's say we have a complex task computing an expensive value:
  #+begin_src clojure :results none
  (defn fib [x] ; a slow implementation of Fibonacci
    (cond
      (= x 0) 1
      (= x 1) 1
      :else   (+ (fib (dec x))
                 (fib (dec (dec x))))))
  #+end_src

  #+begin_src clojure :results value verbatim :exports both
  (map fib (range 10))
  #+end_src

  #+RESULTS:
  : (1 1 2 3 5 8 13 21 34 55)

  #+begin_src clojure :results output :exports both
  (time (fib 37))
  #+end_src

  #+RESULTS:
  : "Elapsed time: 890.82347 msecs"


  We can improve our fibonacci by parallelizing it using ~via~. ~via~ turns a blocking
  operation into an async operation via an executor. ~m/cpu~ is a fixed threadpool
  bound to number of cpus available.

  #+begin_src clojure :results none
  (defn fib-async [n]
    (m/via m/cpu
           (println 'effect)
           (fib n)))
  #+end_src
  We could also provide a custom executor:
  #+begin_src clojure :results none
  (let [e (java.util.concurrent.Executors/newSingleThreadExecutor)]
    (defn fib-single-thread [n]
      (m/via e (fib n))))
  #+end_src

  But we still face the referential transparency issue: tasks do not share identities. This is not a DAG (Directed Acyclic Graph):

  #+begin_src clojure :results output :exports both
  (time (? (m/timeout 3000 (m/join vector (fib-async 37) (fib-async 37)))))
  #+end_src

  #+RESULTS:
  : effect
  : effect
  : "Elapsed time: 948.132023 msecs"

  Even if we factor out ~(fib-async 37)~, we still don't have a DAG:

  #+begin_src clojure :eval never :results none
  (time (? (m/timeout 3000
                      (let [x-task (fib-async 37)]
                        (m/join vector x-task x-task)))))
  #+end_src

  #+begin_src dot :file ./blogpost0/tree_not_dag_actual.png :exports results
  digraph d{
      ask [label="?"];
      timeout [label="timeout 3000"];
      join [label="join vector"];
      a [label="fib-async 37"];
      b [label="fib-async 37"];

      ask -> timeout;
      timeout -> join;
      join -> a;
      join -> b;
  }
  #+end_src

  #+RESULTS:
  [[file:./blogpost0/tree_not_dag_actual.png]]

  Instead it should look like this:

  #+begin_src dot :file ./blogpost0/tree_not_dag_expected.png :exports results
  digraph d{
      ask [label="?"];
      timeout [label="timeout 3000"];
      join [label="join vector"];
      a [label="fib-async 37"];

      ask -> timeout;
      timeout -> join;
      join -> a;
      join -> a;
  }
  #+end_src

  #+RESULTS:
  [[file:./blogpost0/tree_not_dag_expected.png]]

  We can cheat by only computing the result once:
  #+begin_src clojure :eval never :results none
  (def task
    (sp (let [x (? (fib-async 37))]                         ; compute once
          (? (m/join vector                                 ; join is parallelism
                     (m/sleep 100 x)                        ; parallel sleep
                     (m/sleep 101 x))))))
  #+end_src

  - we create a dag, for the fib;
  - then that finishes, we create a new dag ~(join vector sleep sleep)~;
  - then that finishes, those processes terminate with result and are GC'ed;
  - all dags are GC'ed now;

  But here the DAG is actually always a tree, because of referential
  transparency! In other words there is not a single point in time where a
  process has more than one parent. We have a tree for which the topology varies
  over time, but it's always a tree.

  We will try to make it a real DAG and discover we can't. But before that we
  need to talk about flows.

* Plumbing vs Process Building

  =core.async=, =manifold=, and the simpler =BlockingQueue= differs
  fundamentally from RX streams and =missionary=: in the former streams have
  identities while in the later composition is referencially transparent. It
  appears quite clearly with the ~map~ operation:

  #+begin_src clojure :eval never
  (doc 'clojure.core.async/map)
  #+end_src

  #+begin_quote
  "Takes a function and a collection of source channels, and *returns a channel*
  which contains the values produced by applying f to the set of first items taken
  from each source channel […]
  #+end_quote

  ~clojure.core.async/map~ does plumbing. Once values flow in those pipes,
  nothing can prevent a new pipe to be attached upstream or downstream.

  RX and missionary instead composes functional values to build a process. No
  value flows until the process is started. While channels have identities, RX
  streams are referencially transparent. In Clojure, both have a functional
  interface but only RX streams are functional constructs.

  Functional constructs follows functional composition rules, as one comes after
  (~∘~) the other. This process steps ordering and separation of build time vs
  run time gives us supervision for free.

** Processes Hierarchy

   Supervision is the best benefit from the referentially transparent
   (functional) approach. A crashing process can forward an exception to its
   parent, or interrupt its children.

   Example: ~join~ must terminate all children if one of them crashes, then
   notifies its parent. Crashing signals upwards, canceling signals downwards.

   #+begin_src clojure :eval never :results none
   (m/join vector           ; parent task
           crashing-task    ; will crash, so the parent will crash
           regular-task     ; should be canceled because the parent is crashed
           )
   #+end_src

   This is trivial in a tree (hierarchical) topology, but in a DAG there might
   be multiple parents, and none are preferred.

   Earlier we had to cheat with parallelizing and we now discover a tree
   topology introduces signaling ambiguities. The need of a real DAG is getting
   clearer.

** Diamonds and Glitches

   In reactive streams, a diamond glitch happens when a node receives
   intermediate state as input. Here is an example of a glitch, where node ~d~
   receives the value of ~b~ while ~c~ is not computed yet.

   #+begin_src dot :file ./blogpost0/diamond_broken_0.png :exports none :results none
   digraph d{
       a [label="a\nø"]
       b [label="b\n(inc a)\nø"]
       c [label="c\n(dec a)\nø"]
       d [label="d\n(vector b c)\nø"]
       a -> b
       a -> c
       b -> d
       c -> d
   }
   #+end_src

   #+begin_src dot :file ./blogpost0/diamond_broken_1.png :exports none :results none
   digraph d{
       a [label="a\n0"]
       b [label="b\n(inc a)\nø"]
       c [label="c\n(dec a)\nø"]
       d [label="d\n(vector b c)\nø"]
       a -> b
       a -> c
       b -> d
       c -> d
   }
   #+end_src

   #+begin_src dot :file ./blogpost0/diamond_broken_2.png :exports none :results none
   digraph d{
       a [label="a\n0"]
       b [label="b\n(inc a)\n1"]
       c [label="c\n(dec a)\nø"]
       d [label="d\n(vector b c)\nø"]
       a -> b
       a -> c
       b -> d
       c -> d
   }
   #+end_src

   #+begin_src dot :file ./blogpost0/diamond_broken_3.png :exports none :results none
   digraph d{
       a [label="a\n0"]
       b [label="b\n(inc a)\n1"]
       c [label="c\n(dec a)\nø"]
       d [label="d\n(vector b c)\n[1 ø]"]
       a -> b
       a -> c
       b -> d
       c -> d
   }
   #+end_src

   #+begin_src dot :file ./blogpost0/diamond_broken_4.png :exports none :results none
   digraph d{
       a [label="a\n0"]
       b [label="b\n(inc a)\n1"]
       c [label="c\n(dec a)\n-1"]
       d [label="d\n(vector b c)\n[1 ø]"]
       a -> b
       a -> c
       b -> d
       c -> d
   }
   #+end_src


   #+begin_src dot :file ./blogpost0/diamond_broken_5.png :exports none :results none
   digraph d{
       a [label="a\n0"]
       b [label="b\n(inc a)\n1"]
       c [label="c\n(dec a)\n-1"]
       d [label="d\n(vector b c)\n[1 -1]"]
       a -> b
       a -> c
       b -> d
       c -> d
   }
   #+end_src

   #+begin_src shell :results output :exports none
   convert -dispose previous -delay 250 -loop 0 ./blogpost0/diamond_broken_* ./blogpost0/diamond_broken.gif
   #+end_src

   #+RESULTS:

   [[file:./blogpost0/diamond_broken.gif]]

   This happens when nodes are autonomous. Plumbing channels together or using a
   classic Observable/Observer pattern produces glitches as soon as a diamond
   happens.

   ~d~ being a join node, it should wait for all of it's input to be in a ready
   state. We call this a Propagation Cycle or a Propagation Frame. Here is our
   same diamond without glitch:

   #+begin_src dot :file ./blogpost0/diamond_ok_0.png :exports none :results none
   digraph d{
       a [label="a\nø"]
       b [label="b\n(inc a)\nø"]
       c [label="c\n(dec a)\nø"]
       d [label="d\n(vector b c)\nø"]
       a -> b
       a -> c
       b -> d
       c -> d
   }
   #+end_src

   #+begin_src dot :file ./blogpost0/diamond_ok_1.png :exports none :results none
   digraph d{
       a [label="a\n0"]
       b [label="b\n(inc a)\nø"]
       c [label="c\n(dec a)\nø"]
       d [label="d\n(vector b c)\nø"]
       a -> b
       a -> c
       b -> d
       c -> d
   }
   #+end_src

   #+begin_src dot :file ./blogpost0/diamond_ok_2.png :exports none :results none
   digraph d{
       a [label="a\n0"]
       b [label="b\n(inc a)\n1"]
       c [label="c\n(dec a)\nø"]
       d [label="d\n(vector b c)\nø"]
       a -> b
       a -> c
       b -> d
       c -> d
   }
   #+end_src

   #+begin_src dot :file ./blogpost0/diamond_ok_3.png :exports none :results none
   digraph d{
       a [label="a\n0"]
       b [label="b\n(inc a)\n1"]
       c [label="c\n(dec a)\n-1"]
       d [label="d\n(vector b c)\nø"]
       a -> b
       a -> c
       b -> d
       c -> d
   }
   #+end_src

   #+begin_src dot :file ./blogpost0/diamond_ok_4.png :exports none :results none
   digraph d{
       a [label="a\n0"]
       b [label="b\n(inc a)\n1"]
       c [label="c\n(dec a)\n-1"]
       d [label="d\n(vector b c)\n[1 -1]"]
       a -> b
       a -> c
       b -> d
       c -> d
   }
   #+end_src

   #+begin_src shell :results output :exports none
   convert -dispose previous -delay 250 -loop 0 ./blogpost0/diamond_ok_* ./blogpost0/diamond_ok.gif
   #+end_src

   #+RESULTS:

   [[file:./blogpost0/diamond_ok.gif]]


* Reactor

  We've seen that:
  - parallelizing tasks in a hierarchical topology requires a real DAG;
  - in a DAG, nodes might have multiple parents in which case none are preferred
    to be the supervisor;
  - a diamond case might introduce glitches if nodes don't run in the "right"
    order.

  A reactor addresses all these concerns.

** Supervising n-parents nodes

   A reactor is a top-level supervisor, supervising all nodes under its context.
   When a node ~n~ got more than one parents (DAG case) then none of them are
   preferred to be the supervisor. So if ~n~ crashes, the reactor is signaled
   and will crash in turn, canceling all nodes underneath it.

** Solving glitches

   Our functional constructs composes in order. We therefore know a node will
   always run *after* its dependencies. The diamond case remains problematic,
   but knowing all nodes underneath it, the reactor can plan them to run in
   topological order.

   #+begin_src dot :file ./blogpost0/diamond_reactor_0.png :exports none :results none
   digraph d{
       subgraph cluster_reactor{
           label = "Reactor";
           style = filled;
           color = "lightgray";
           node [style = filled; color = "white"];
           a [label="a\nø"; xlabel="1"];
           b [label="b\n(inc a)\nø"; xlabel="2"];
           c [label="c\n(dec a)\nø"; xlabel="3"];
           d [label="d\n(vector b c)\nø"; xlabel="4"];
           a -> b;
           a -> c;
           b -> d;
           c -> d;
       }
   }
   #+end_src

   #+begin_src dot :file ./blogpost0/diamond_reactor_1.png :exports none :results none
   digraph d{
    subgraph cluster_reactor{
       label = "Reactor";
       style = filled;
       color = "lightgray";
       node [style = filled; color = "white"];
       a [label="a\n0"; xlabel="1"];
       b [label="b\n(inc a)\nø"; xlabel="2"];
       c [label="c\n(dec a)\nø"; xlabel="3"];
       d [label="d\n(vector b c)\nø"; xlabel="4"];
       a -> b;
       a -> c;
       b -> d;
       c -> d;
    }
   }
   #+end_src

   #+begin_src dot :file ./blogpost0/diamond_reactor_2.png :exports none :results none
   digraph d{
    subgraph cluster_reactor{
       label = "Reactor";
       style = filled;
       color = "lightgray";
       node [style = filled; color = "white"];
       a [label="a\n0"; xlabel="1"];
       b [label="b\n(inc a)\n1"; xlabel="2"];
       c [label="c\n(dec a)\nø"; xlabel="3"];
       d [label="d\n(vector b c)\nø"; xlabel="4"];
       a -> b;
       a -> c;
       b -> d;
       c -> d;
    }
   }
   #+end_src

   #+begin_src dot :file ./blogpost0/diamond_reactor_3.png :exports none :results none
   digraph d{
    subgraph cluster_reactor{
       label = "Reactor";
       style = filled;
       color = "lightgray";
       node [style = filled; color = "white"];
       a [label="a\n0"; xlabel="1"];
       b [label="b\n(inc a)\n1"; xlabel="2"];
       c [label="c\n(dec a)\n-1"; xlabel="3"];
       d [label="d\n(vector b c)\nø"; xlabel="4"];
       a -> b;
       a -> c;
       b -> d;
       c -> d;
    }
   }
   #+end_src

   #+begin_src dot :file ./blogpost0/diamond_reactor_4.png :exports none :results none
   digraph d{
    subgraph cluster_reactor{
       label = "Reactor";
       style = filled;
       color = "lightgray";
       node [style = filled; color = "white"];
       a [label="a\n0"; xlabel="1"];
       b [label="b\n(inc a)\n1"; xlabel="2"];
       c [label="c\n(dec a)\n-1"; xlabel="3"];
       d [label="d\n(vector b c)\n[1 -1]"; xlabel="4"];
       a -> b;
       a -> c;
       b -> d;
       c -> d;
    }
   }
   #+end_src

   #+begin_src shell :results output :exports none
   convert -dispose previous -delay 250 -loop 0 ./blogpost0/diamond_reactor_* ./blogpost0/diamond_reactor.gif
   #+end_src

   #+RESULTS:

   [[file:./blogpost0/diamond_reactor.gif]]

* Discrete Flows

  A task is a program that eventually produces *one* value, while a flow is a
  program that eventually produces *multiple* values. Value production is always
  asynchronous. Being backed by IO, we don't know when the values are produced.

  If you think "Reactive Streams", you can have a look at the [[https://github.com/leonoel/flow][Flow spec]].

  Just like ~sp~ is for sequential composition, ~ap~ is for flow composition.
  ~ap~ means Ambiguous Process.

  #+begin_src clojure :results none
  (ap 42) ;; A flow that will produce `42`, once, then terminate.
  (ap (println (?! (m/enumerate [1 2 3])))) ;; will print `1`, then `2`, then `3`, then terminate.
  #+end_src

  NOTE: ~?!~ is pronounced =fork-switch=.
  # because we can consider ~ap~ to be an asynchronous List monad, backed by IO instead of computations.

  Ambiguous Processes can combine tasks and flows:

  #+begin_src clojure :eval never :results none
  (defn emit-sleep [delays]
    ;; flow
    (ap (let [x (?! (m/enumerate delays))]
          ;; task
          (? (m/sleep x x)))))
  #+end_src

  They composes dynamically like tasks:
  #+begin_src clojure :eval never :results none
  (ap (let [a (?? (emit-sleep [301 302 303]))]
        (?? (if (odd? a)
              (emit-sleep [a])
              (emit-sleep [(inc a)])))))
  #+end_src

  Ambiguous Processes are sequential computations lifted into a list because
  each form can have more than one result. AP is still sequential unless you use
  ~?=~ (~fork-gather~ [fn:2]) operator which introduces parallelism. The
  resulting flow is sequential, all parallel branches are gathered. They are
  racing for the final ordering in the result flow. We can think of AP as an
  asynchronous List monad, backed by IO instead of computations.

* WIP - Continuous Flows

   The thesis of continuous flows is that it is a special optimzation case of
   discrete flows where each new value invalidates the previous one (e.g. there
   is no history sensitivity). that means you can defer computation until the
   value is asked for.


  #+begin_comment
  (tests
    "discrete flows"


    ; the thesis of continuous flows is that some computations are RT (other than
    ; compute resources consumed) and we just want to incrementally maintain them to make
    ; them update faster as an optimization
    ; this is wrong, you can have eager incremental maintenance
    ;
    ; examples: reactjs, spreadsheets, database queries
    ;
    ; Leo says this is technically true but not sure how it helps
    ;
    ; Leo's words:
    ; you want to sample lazily because you don't know in advance when (at which point in time)
    ; the value will actually be needed
    ; the computation of the dag should be triggered by the consumer

    ; Is incremental a properly defined word? or just Jane Street? I dont know
    ;
    ;  continuous flows make sense if each new value invalidates the previous one
    ; no history sensitivity
    ; no

    ; try again
    ; the thesis of continuous flows is that it is a special optimzation case of discrete flows
    ; where each new value invalidates the previous one (e.g. there is no history sensitivity).
    ; that means you can defer computation until the value is asked for.
    ;    reactjs is discrete, but could actually be faster if continuous?
    ;    it depends how you use it ... this is the confusion

    ; ReactDOM.render()
    ; this attaches a reactor to the document and runs forever ... its all about effects
    ; manage the effect of the dom patches
    ; manage the effects of computation of HTML view values
    ;    incremental maintenance with prevProps memoization
    ; feeding the dom events into user logic
    ; reactjs has a component lifecycle

    ; React is using an unclear approach
    ; shouldComponentUpdate
    ; this is made mandatory by the impedance mismatch between FP and Javascript

    ; therefore we learn that Reactjs has a lot in common with continuous flows
    ; This is why FRP failed to gain traction in frontend dev -
    ; discrete FRP is not what you want for frontend dom rendering

    ; the value prop of react is to provide functional programming interface to the dom
    ;
    ;

    ; so twitter is history sensitive as it counts the number of like commands,
    ; so it must be discrete


    ; RX latest same thing as missionary latest ... runs fn each time an input changes
    ; but it's fully eager because underlying is eager so it produces glitches.
    ; you can't represent the scenario where
    ;     two values change at the same time so the fn should only be run once
    ; ^ that's the glitch we want to avoid.


    ; if SP composes sequentially like IO monad
    ; how does AP compose?
    ; it's an async list monad, backed by IO instead of computations
    (ap (println (?! (m/enumerate [1 2 3]))))
    (for [x (m/enumerate [1 2 3])] (println x))               ; pseudocode (not async)
    (mapcat println (m/enumerate [1 2 3]))                    ; pseudocode (not async)

    ; This is one way to think about flows
    ; Leo: it is better to first explain what a flow is
    ; and then how to compose them.

    )
  #+end_comment

* Source                                                           :noexport:
  #+begin_comment clojure :eval never :exports none
  (tests

    ; Effect was run only once (which is not parallelism, we cheated)
    ; With tasks we can usually cheat in this way, but with flows
    ; it becomes much more complicated
    ; usually or always? Not sure

    ; The real answer to fib is to define a SP that computes the fib result
    ; and only after that call the join
    ; the missionary answer is to arrange expensive computations by hand
    ; our use our dataflow macro to assume the computation is RT and thus incrementally maintain

    ; Another (heavy) solution to this problem is "Reactor"
    ; There are simpler ways to fix this than reactor
    ; for more complex use cases, reactor makes sense

    ; Note can always turn a task into a flow with ap
    ; tasks are strictly more powerful
    )

  ; Two kinds of flows, discrete and continuous

  ;; # HERE
  ; Aggregate also is not a primitive we use in real world. Just for testing

  (tests
    "flow diamond case is interesting"
    ; illustrate the motivator for reactor

    ; we need a reactive computation where some branches are expensive



    (def >needle (m/watch !needle)) (def !needle (atom "alice"))
    (def >open (m/watch !open)) (def !open (atom true))

    (def flow
      (ap
        (println                                              ;need effect for this to make sense
          (let [needle (?! >needle)]
            (vector
              (?! (submissions needle))
              (if (?! >open)
                (?! (submissions-detail "tempid"))
                ::nothing))))))

    ; ap has no parallelism
    ; m/latest is the operator that introduces parallelism
    ; because flows are RT, intermediate computations are not reused
    ;   (bc this requires internal state shared across calls)
    ; this is the same problem as with tasks

    ; without reactors, at runtime the computation will always be a tree

    (let [e (java.util.concurrent.Executors/newSingleThreadExecutor)]
      (defn submissions' [n]
        ; via turns a blocking op into an async op via an executor
        ; cpu is a fixed threadpool bound to number of cpus available
        ; make it async, returns a task value
        (m/via e
          #_m/cpu
          (datomic.api/q ...))))
    ; same as ap basically

    (defn submissions! [needle] (d/q ... needle))
    (defn submissions [needle] (m/via _ (d/q ... needle)))
    ; does this do the effect or return a value that performs the effect
    (defn submissions-detail! [needle] (d/q ... needle))
    (defn submissions-detail [needle] (m/via _ (d/q ... needle)))

    (def flow
      (m/reactor
        (ap
          (println
            (let []                        ; fork
              (m/latest vector
                ; side effects in ap blocks must not block thread! prinln is ok. fib is bad!
                ; missionary assumes ops are nonblocking
                #_(ap (submissions! (?! >needle)))              ; blocks thread for everyone
                #_(ap (submissions! (?! >needle)))              ; blocks thread for everyone
                (ap (? (submissions (?! >needle))))           ; parallel execution
                (ap (? (submissions (?! >needle))))           ; parallel execution



                (ap
                  (let [open (?! >open)]
                    (? (m/via _ (if open
                                  (submissions-detail! needle)
                                  ::nothing)))))

                (ap
                  (if (?! >open)
                    (?! (submissions-detail "tempid"))
                    ::nothing))))))))

    (def flow
      (m/latest (comp println vector)
        (ap (? (submissions (?! >needle))))
        (ap (if-let [open (?! >open)]
              (? (submissions-detail open))
              ::nothing))))

    ; cant do this, it doesn't make sense
    ; -- (? flow)
    ; because flows are something that produce multiple values
    ; and this notation suggests we are waiting on a single value

    ; So all flows are started like this:
    (def !out (flow #(prn :notify) #(prn :terminate)))
    ; :notify
    ; the flow is now running

    @!out := _

    (reset !needle "charlie")
    ; :notify
    @!out := _

    (reset !open false)
    ; :notify
    @!out := _

    ; SO this is fast without reactor
    ; so we need a new example to add reactor



    (def flow
      (dataflow
        (println                                              ;need effect for this to make sense
          (let [needle (<- >needle)
                open (<- >open)]
            (vector
              (submissions needle)
              (if open
                (<- (submissions-detail "tempid"))
                ::nothing))))))

    (reset! >open false)
    ; reset will restart the continuation/fiber from the point
    ; where we listen to the atom

    (reset! >needle "bob")
    ; this will restart the fiber from (?! >needle) and compose sequentially from here
    ; thus recomputing the popover as well even though the popover did not change.

    ; this does not optimize because the parallelism is not explicit

    ; reactor is the difference between sequential and incremental
    ; the reactor
    ; adds internal state to the flow (across input changes over time) so that past values of nodes can be reused
    ; you assign identities to nodes so as to not recompute the whole chain


    ; create a diamond shape
    (ap
      (let [x (?! (m/enumerate (range 3)))]
        (vector (inc x) (dec x)))

      )




    ; This is an IO recipe for a async stream
    ; If you were to run it you get the effect
    ; but no internal state is shared between runs! It is RT

    ; the reactor lets you share state across runs to incrementally maintain


    (reset! >open false)
    ; This is composition has no parallelism
    ; without a reactor
    ; we need to name the reuse points and create a DAG


    ; reactive fib
    (defn fib [x]
      (m/!)
      (cond
        (= x 0) 1
        (= x 1) 1
        () (+ (fib (dec x))
             (fib (dec (dec x))))))



    (let [e (java.util.concurrent.Executors/newSingleThreadExecutor)]
      (defn fib-async [n]
        ; via turns a blocking op into an async op via an executor
        ; cpu is a fixed threadpool bound to number of cpus available
        (m/via e
          #_m/cpu
          (println 'effect)
          (fib n))))

    )








  (tests
    "Reactor"
    ; Reactor is about reusing processes and assigning
    ; an identity to a process in order to reuse it

    ; It doesn't make much sense in tasks ?
    (m/reactor
      )

    )



  (tests
    "reactor"

    ; Why do we need a reactor?
    ; If you only have flows, you can only represent hierarchical processes
    ; The topology is a hierarchy because that's how function composition works
    ; With only flows you can't have DAG topologies

    (vector ~x ~x)                                            ; simplest dag
    ; This is not a dag because the two branches of vector are not run in parallel



    (ap


      (let [x (?? (emit-sleep [1 2 3]))]
        (?)))

    )

  (tests
    "continuous flows")
#+end_comment

* Footnotes

[fn:1] This is a design choice, =core.async= made a different choice by providing =<!= and =<!!= for non-blocking and blocking operations, respectively.

[fn:2] In RX, it would be called ~flatMap~.
